---
title: 'testv2'
categories: [HackTheBox]
tags: [Linux, Easy, Pluck]
image: images/Mr Robot/Mr Robot.jpg
---
**Mr. Robot** is an **medium** rated room on **TryHackMe** inspired by the Mr. Robot TV series. The challenge begins with a web server hosting a WordPress site that contains clues and vulnerabilities. By enumerating the web server, you discover hidden directories and files, leading to the extraction of sensitive information. Gaining initial access involves using cracked credentials found through wordlists and exploiting the WordPress setup.


# 1.Initial Reconnaissance and Scanning:
The first phase of any Capture The Flag (CTF) challenge is information gathering. Our goal here is to identify what services are running on the target machine and which ports are open. This intelligence sets the stage for future attacks. 
### Nmap Scan:
Use Nmap to scan the target's open ports, services, and versions:

```console
nmap -sC -sV -oN nmap_scan <Target_IP>

``` 
`-sC:` Enables default scripts, often revealing common vulnerabilities.  
`-sV:` Detects service/version information, such as Apache, OpenSSH, etc.  
`-oN` nmap_scan: Saves the output into a file named nmap_scan for later reference.

### Understanding the Results:
Look for ports such as:

**Port 80** (HTTP): Likely indicates a website is running.   
**Port 443** (HTTPS): Secure HTTP services.   
**Port 22** (SSH): Useful later for remote access.  

# 2. Web Enumeration :

With **port 80 (HTTP)** open, it's time to explore the website for hidden vulnerabilities or clues. This includes both manual inspection and automated enumeration of directories.

### Inspect the Website:
Visit the site at `http://<Target_IP>`. The website is themed around the **Mr. Robot** show, but stay focused on finding clues. Check the **page source** for hidden comments or links that developers might have left behind.

**robots.txt File:**
The `robots.txt` file can contain sensitive or hidden information that isn't meant for users. Access it with:

```console
curl http://<Target_IP>/robots.txt
``` 


You'll find two key pieces of information:

**●fsocity.dic:** A wordlist for brute-forcing passwords.   
**●key-1-of-3.txt:** The first flag. Retrieve it from `http://<Target_IP>/key-1-of-3.txt`.
Download both files:
```console
wget http://<Target_IP>/fsocity.dic
wget http://<Target_IP>/key-1-of-3.txt
``` 
The **fsocity.dic** file is a wordlist we will use later for brute-forcing the login credentials.

# 3. Directory Brute-Forcing
Next, we perform directory brute-forcing to uncover hidden pages or admin areas. This step can lead to further insights about the target's web structure.

### Gobuster or Dirb Scan: